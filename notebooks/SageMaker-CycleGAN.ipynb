{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* SageMaker training for Cycle-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::019326146125:role/service-role/AmazonSageMaker-ExecutionRole-20190407T165524\n"
     ]
    }
   ],
   "source": [
    "BUCKET='markstrefford-art-1'\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "pytorch_estimator = PyTorch(entry_point='train.py',\n",
    "                            role=role,\n",
    "                            train_instance_type='ml.p3.2xlarge',  \n",
    "                            train_instance_count=1,\n",
    "                            framework_version='1.0.0',\n",
    "                            source_dir='../pytorch-CycleGAN-and-pix2pix-master',\n",
    "                            output_path='s3://{}/cityscapes/model'.format(BUCKET),\n",
    "                            train_volume_size=70,\n",
    "                            hyperparameters = {\n",
    "                                # 'num_epochs': 1,\n",
    "                                'name': 'city_cyclegan',\n",
    "                                'model': 'cycle_gan',\n",
    "                                'pool_size': 50  #,\n",
    "                                # 'no_dropout': True\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-04 17:47:50 Starting - Starting the training job...\n",
      "2019-08-04 17:47:52 Starting - Launching requested ML instances......\n",
      "2019-08-04 17:48:51 Starting - Preparing the instances for training.........\n",
      "2019-08-04 17:50:43 Downloading - Downloading input data.........\n",
      "2019-08-04 17:52:12 Training - Training image download completed. Training in progress.\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-08-04 17:52:12,821 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-08-04 17:52:12,846 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-08-04 17:52:14,265 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-08-04 17:52:14,680 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-08-04 17:52:14,680 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-08-04 17:52:14,680 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-08-04 17:52:14,680 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting torch>=0.4.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\u001b[0m\n",
      "\u001b[31mCollecting torchvision>=0.2.1 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\u001b[0m\n",
      "\u001b[31mCollecting dominate>=2.3.1 (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/64/593e829416c951eb35c2246430d59b86f640087e29e71f32632bcde5d0f7/dominate-2.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting visdom>=0.1.8.3 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/97/c4/5f5356fd57ae3c269e0e31601ea6487e0622fedc6756a591e4a5fd66cc7a/visdom-0.1.8.8.tar.gz (1.4MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->-r requirements.txt (line 1)) (1.16.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (6.0.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (1.12.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.3.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.22.0)\u001b[0m\n",
      "\u001b[31mCollecting tornado (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/78/2d2823598496127b21423baffaa186b668f73cd91887fcef78b6eade136b/tornado-6.0.3.tar.gz (482kB)\u001b[0m\n",
      "\u001b[31mCollecting pyzmq (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/92/ea8f20560d5f1d0c6eb3c7c67ca72abfb97307f4e6494fc05cc7c37904cf/pyzmq-18.0.2-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\u001b[0m\n",
      "\u001b[31mCollecting torchfile (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting websocket-client (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2019.3.9)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.25.3)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.8)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (3.0.4)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: visdom, train, tornado, torchfile\n",
      "  Running setup.py bdist_wheel for visdom: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for visdom: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/87/ce/a5023722374ca73b57fc8d4284ba6f973c01219b3c385a07e0\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-25h8xjiv/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for tornado: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for tornado: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/bf/40/2f6ef700f48401ca40e5e3dd7d0e3c0a90e064897b7fe5fc08\n",
      "  Running setup.py bdist_wheel for torchfile: started\n",
      "  Running setup.py bdist_wheel for torchfile: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\u001b[0m\n",
      "\u001b[31mSuccessfully built visdom train tornado torchfile\u001b[0m\n",
      "\u001b[31msagemaker-pytorch-container 1.1 has requirement torch==1.0.0, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mInstalling collected packages: torch, torchvision, dominate, tornado, pyzmq, torchfile, websocket-client, visdom, train\n",
      "  Found existing installation: torch 1.0.0\n",
      "    Uninstalling torch-1.0.0:\u001b[0m\n",
      "\u001b[31m      Successfully uninstalled torch-1.0.0\u001b[0m\n",
      "\u001b[31m  Found existing installation: torchvision 0.2.1\n",
      "    Uninstalling torchvision-0.2.1:\n",
      "      Successfully uninstalled torchvision-0.2.1\u001b[0m\n",
      "\u001b[31mSuccessfully installed dominate-2.4.0 pyzmq-18.0.2 torch-1.1.0 torchfile-0.1.0 torchvision-0.3.0 tornado-6.0.3 train-1.0.0 visdom-0.1.8.8 websocket-client-0.56.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-08-04 17:53:01,110 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"pool_size\": 50,\n",
      "        \"name\": \"city_cyclegan\",\n",
      "        \"model\": \"cycle_gan\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-08-04-17-47-47-442\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://markstrefford-art-1/sagemaker-pytorch-2019-08-04-17-47-47-442/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"model\":\"cycle_gan\",\"name\":\"city_cyclegan\",\"pool_size\":50}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://markstrefford-art-1/sagemaker-pytorch-2019-08-04-17-47-47-442/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model\":\"cycle_gan\",\"name\":\"city_cyclegan\",\"pool_size\":50},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-08-04-17-47-47-442\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://markstrefford-art-1/sagemaker-pytorch-2019-08-04-17-47-47-442/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--model\",\"cycle_gan\",\"--name\",\"city_cyclegan\",\"--pool_size\",\"50\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_HP_POOL_SIZE=50\u001b[0m\n",
      "\u001b[31mSM_HP_NAME=city_cyclegan\u001b[0m\n",
      "\u001b[31mSM_HP_MODEL=cycle_gan\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --model cycle_gan --name city_cyclegan --pool_size 50\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: /opt/ml/model                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /opt/ml/input/data/training   \n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          #011[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             #011[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "               n_layers_D: 3                             \n",
      "                     name: city_cyclegan                 #011[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \u001b[0m\n",
      "\u001b[31m----------------- End -------------------\u001b[0m\n",
      "\u001b[31mdataset [UnalignedDataset] was created\u001b[0m\n",
      "\u001b[31mThe number of training images = 6640\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31minitialize network with normal\u001b[0m\n",
      "\u001b[31minitialize network with normal\u001b[0m\n",
      "\u001b[31minitialize network with normal\u001b[0m\n",
      "\u001b[31minitialize network with normal\u001b[0m\n",
      "\u001b[31mmodel [CycleGANModel] was created\u001b[0m\n",
      "\u001b[31m---------- Networks initialized -------------\u001b[0m\n",
      "\u001b[31m[Network G_A] Total number of parameters : 11.378 M\u001b[0m\n",
      "\u001b[31m[Network G_B] Total number of parameters : 11.378 M\u001b[0m\n",
      "\u001b[31m[Network D_A] Total number of parameters : 2.765 M\u001b[0m\n",
      "\u001b[31m[Network D_B] Total number of parameters : 2.765 M\u001b[0m\n",
      "\u001b[31m-----------------------------------------------\u001b[0m\n",
      "\u001b[31mException in user code:\u001b[0m\n",
      "\u001b[31m------------------------------------------------------------\u001b[0m\n",
      "\u001b[31mCould not connect to Visdom server. \n",
      " Trying to start a server....\u001b[0m\n",
      "\u001b[31mCommand: /usr/bin/python -m visdom.server -p 8097 &>/dev/null &\u001b[0m\n",
      "\u001b[31mcreate web directory /opt/ml/model/city_cyclegan/web...\u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 100, time: 0.183, data: 0.288) D_A: 0.385 G_A: 0.273 cycle_A: 4.799 idt_A: 1.262 D_B: 0.288 G_B: 0.370 cycle_B: 2.815 idt_B: 2.380 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 200, time: 0.182, data: 0.001) D_A: 0.333 G_A: 0.366 cycle_A: 3.276 idt_A: 0.822 D_B: 0.230 G_B: 0.283 cycle_B: 1.962 idt_B: 1.526 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 300, time: 0.181, data: 0.001) D_A: 0.299 G_A: 0.364 cycle_A: 2.432 idt_A: 1.219 D_B: 0.321 G_B: 0.233 cycle_B: 2.482 idt_B: 1.059 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 400, time: 0.525, data: 0.001) D_A: 0.308 G_A: 0.290 cycle_A: 2.835 idt_A: 0.911 D_B: 0.298 G_B: 0.493 cycle_B: 1.965 idt_B: 1.334 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 500, time: 0.184, data: 0.002) D_A: 0.342 G_A: 0.147 cycle_A: 2.096 idt_A: 0.770 D_B: 0.199 G_B: 0.475 cycle_B: 3.169 idt_B: 1.012 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 600, time: 0.181, data: 0.001) D_A: 0.230 G_A: 0.287 cycle_A: 2.287 idt_A: 1.046 D_B: 0.345 G_B: 0.351 cycle_B: 2.062 idt_B: 0.956 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 700, time: 0.181, data: 0.001) D_A: 0.241 G_A: 0.307 cycle_A: 1.150 idt_A: 0.930 D_B: 0.262 G_B: 0.474 cycle_B: 2.159 idt_B: 0.505 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 800, time: 0.588, data: 0.001) D_A: 0.323 G_A: 0.366 cycle_A: 1.826 idt_A: 0.990 D_B: 0.259 G_B: 0.325 cycle_B: 2.015 idt_B: 1.013 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 900, time: 0.182, data: 0.001) D_A: 0.263 G_A: 0.531 cycle_A: 2.493 idt_A: 1.126 D_B: 0.233 G_B: 0.198 cycle_B: 2.549 idt_B: 1.019 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1000, time: 0.182, data: 0.001) D_A: 0.242 G_A: 0.162 cycle_A: 1.547 idt_A: 1.288 D_B: 0.230 G_B: 0.545 cycle_B: 2.867 idt_B: 0.838 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1100, time: 0.182, data: 0.002) D_A: 0.291 G_A: 0.275 cycle_A: 1.996 idt_A: 0.999 D_B: 0.414 G_B: 0.313 cycle_B: 2.167 idt_B: 0.730 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1200, time: 0.644, data: 0.001) D_A: 0.277 G_A: 0.255 cycle_A: 2.133 idt_A: 0.646 D_B: 0.120 G_B: 0.404 cycle_B: 1.291 idt_B: 0.938 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1300, time: 0.182, data: 0.002) D_A: 0.192 G_A: 0.391 cycle_A: 1.923 idt_A: 0.522 D_B: 0.405 G_B: 0.304 cycle_B: 1.380 idt_B: 1.002 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1400, time: 0.182, data: 0.001) D_A: 0.257 G_A: 0.419 cycle_A: 1.756 idt_A: 0.875 D_B: 0.173 G_B: 0.330 cycle_B: 1.978 idt_B: 0.857 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1500, time: 0.182, data: 0.001) D_A: 0.277 G_A: 0.224 cycle_A: 1.632 idt_A: 0.649 D_B: 0.229 G_B: 0.146 cycle_B: 1.824 idt_B: 0.768 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1600, time: 0.537, data: 0.001) D_A: 0.252 G_A: 0.182 cycle_A: 1.778 idt_A: 0.496 D_B: 0.286 G_B: 0.440 cycle_B: 1.178 idt_B: 0.784 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1700, time: 0.182, data: 0.002) D_A: 0.181 G_A: 0.253 cycle_A: 2.074 idt_A: 1.137 D_B: 0.188 G_B: 0.583 cycle_B: 2.480 idt_B: 0.618 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1800, time: 0.184, data: 0.001) D_A: 0.262 G_A: 0.174 cycle_A: 2.625 idt_A: 0.641 D_B: 0.278 G_B: 0.253 cycle_B: 1.516 idt_B: 1.227 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 1900, time: 0.182, data: 0.001) D_A: 0.228 G_A: 0.451 cycle_A: 1.739 idt_A: 1.001 D_B: 0.493 G_B: 0.507 cycle_B: 2.084 idt_B: 0.891 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2000, time: 0.623, data: 0.002) D_A: 0.242 G_A: 0.351 cycle_A: 1.609 idt_A: 0.839 D_B: 0.290 G_B: 0.484 cycle_B: 1.883 idt_B: 0.659 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2100, time: 0.183, data: 0.001) D_A: 0.318 G_A: 0.225 cycle_A: 2.583 idt_A: 1.849 D_B: 0.126 G_B: 0.088 cycle_B: 3.541 idt_B: 1.209 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2200, time: 0.183, data: 0.002) D_A: 0.231 G_A: 0.272 cycle_A: 3.197 idt_A: 0.811 D_B: 0.216 G_B: 0.422 cycle_B: 1.636 idt_B: 1.184 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2300, time: 0.181, data: 0.002) D_A: 0.505 G_A: 0.415 cycle_A: 1.292 idt_A: 0.476 D_B: 0.355 G_B: 0.321 cycle_B: 1.038 idt_B: 0.600 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2400, time: 0.568, data: 0.001) D_A: 0.134 G_A: 0.307 cycle_A: 1.446 idt_A: 2.372 D_B: 0.565 G_B: 0.192 cycle_B: 4.430 idt_B: 0.793 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2500, time: 0.182, data: 0.001) D_A: 0.275 G_A: 0.541 cycle_A: 1.515 idt_A: 0.890 D_B: 0.429 G_B: 0.210 cycle_B: 1.945 idt_B: 0.787 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2600, time: 0.182, data: 0.001) D_A: 0.296 G_A: 0.175 cycle_A: 2.650 idt_A: 0.702 D_B: 0.466 G_B: 0.348 cycle_B: 1.788 idt_B: 0.975 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2700, time: 0.182, data: 0.001) D_A: 0.265 G_A: 0.222 cycle_A: 1.538 idt_A: 0.708 D_B: 0.253 G_B: 0.262 cycle_B: 1.550 idt_B: 0.586 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2800, time: 0.621, data: 0.002) D_A: 0.238 G_A: 0.427 cycle_A: 2.664 idt_A: 0.405 D_B: 0.296 G_B: 0.485 cycle_B: 0.927 idt_B: 1.085 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 2900, time: 0.182, data: 0.002) D_A: 0.239 G_A: 0.282 cycle_A: 3.323 idt_A: 0.761 D_B: 0.242 G_B: 0.565 cycle_B: 1.911 idt_B: 1.396 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3000, time: 0.182, data: 0.001) D_A: 0.267 G_A: 0.196 cycle_A: 1.889 idt_A: 0.684 D_B: 0.219 G_B: 0.277 cycle_B: 1.586 idt_B: 1.032 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3100, time: 0.182, data: 0.002) D_A: 0.262 G_A: 0.676 cycle_A: 2.700 idt_A: 1.177 D_B: 0.294 G_B: 0.170 cycle_B: 2.087 idt_B: 1.089 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3200, time: 0.543, data: 0.001) D_A: 0.356 G_A: 0.129 cycle_A: 1.822 idt_A: 0.580 D_B: 0.314 G_B: 0.446 cycle_B: 1.275 idt_B: 0.715 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3300, time: 0.182, data: 0.002) D_A: 0.173 G_A: 0.218 cycle_A: 1.267 idt_A: 0.966 D_B: 0.321 G_B: 0.625 cycle_B: 1.897 idt_B: 0.597 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3400, time: 0.182, data: 0.001) D_A: 0.201 G_A: 0.206 cycle_A: 1.175 idt_A: 0.800 D_B: 0.474 G_B: 0.758 cycle_B: 1.915 idt_B: 0.447 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3500, time: 0.183, data: 0.001) D_A: 0.289 G_A: 0.309 cycle_A: 2.132 idt_A: 0.865 D_B: 0.082 G_B: 0.237 cycle_B: 1.442 idt_B: 0.722 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3600, time: 0.611, data: 0.002) D_A: 0.472 G_A: 0.297 cycle_A: 1.286 idt_A: 1.374 D_B: 0.280 G_B: 0.153 cycle_B: 2.471 idt_B: 0.618 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3700, time: 0.182, data: 0.002) D_A: 0.275 G_A: 0.365 cycle_A: 1.601 idt_A: 0.929 D_B: 0.134 G_B: 0.341 cycle_B: 1.965 idt_B: 0.832 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3800, time: 0.182, data: 0.001) D_A: 0.239 G_A: 0.491 cycle_A: 1.539 idt_A: 0.767 D_B: 0.421 G_B: 0.073 cycle_B: 2.427 idt_B: 0.671 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 3900, time: 0.182, data: 0.002) D_A: 0.206 G_A: 0.608 cycle_A: 1.666 idt_A: 0.534 D_B: 0.062 G_B: 0.452 cycle_B: 1.347 idt_B: 0.746 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4000, time: 0.478, data: 0.002) D_A: 0.252 G_A: 0.146 cycle_A: 2.169 idt_A: 0.727 D_B: 0.360 G_B: 0.612 cycle_B: 1.558 idt_B: 0.945 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4100, time: 0.182, data: 0.001) D_A: 0.202 G_A: 0.388 cycle_A: 1.088 idt_A: 0.995 D_B: 0.236 G_B: 0.353 cycle_B: 1.826 idt_B: 0.497 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4200, time: 0.182, data: 0.001) D_A: 0.093 G_A: 0.352 cycle_A: 1.535 idt_A: 1.733 D_B: 0.577 G_B: 0.163 cycle_B: 2.944 idt_B: 0.639 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4300, time: 0.183, data: 0.002) D_A: 0.139 G_A: 0.318 cycle_A: 1.768 idt_A: 0.665 D_B: 0.324 G_B: 0.346 cycle_B: 1.484 idt_B: 0.637 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4400, time: 0.524, data: 0.002) D_A: 0.298 G_A: 0.432 cycle_A: 1.840 idt_A: 0.679 D_B: 0.200 G_B: 0.284 cycle_B: 1.372 idt_B: 0.921 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4500, time: 0.181, data: 0.002) D_A: 0.140 G_A: 0.251 cycle_A: 0.968 idt_A: 0.921 D_B: 0.464 G_B: 0.245 cycle_B: 2.043 idt_B: 0.455 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4600, time: 0.182, data: 0.001) D_A: 0.346 G_A: 0.129 cycle_A: 1.386 idt_A: 1.055 D_B: 0.396 G_B: 0.384 cycle_B: 2.114 idt_B: 0.599 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m(epoch: 1, iters: 4700, time: 0.182, data: 0.002) D_A: 0.224 G_A: 0.313 cycle_A: 1.209 idt_A: 0.597 D_B: 0.222 G_B: 0.339 cycle_B: 1.153 idt_B: 0.707 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4800, time: 0.502, data: 0.001) D_A: 0.170 G_A: 0.213 cycle_A: 1.336 idt_A: 0.731 D_B: 0.216 G_B: 0.859 cycle_B: 1.630 idt_B: 0.575 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 4900, time: 0.182, data: 0.002) D_A: 0.298 G_A: 0.763 cycle_A: 1.568 idt_A: 0.995 D_B: 0.250 G_B: 0.515 cycle_B: 2.486 idt_B: 0.642 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5000, time: 0.182, data: 0.001) D_A: 0.238 G_A: 0.125 cycle_A: 1.318 idt_A: 1.021 D_B: 0.209 G_B: 0.487 cycle_B: 2.322 idt_B: 0.606 \u001b[0m\n",
      "\u001b[31msaving the latest model (epoch 1, total_iters 5000)\u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5100, time: 0.182, data: 0.002) D_A: 0.302 G_A: 0.133 cycle_A: 1.635 idt_A: 0.671 D_B: 0.187 G_B: 0.860 cycle_B: 1.381 idt_B: 0.617 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5200, time: 0.498, data: 0.001) D_A: 0.467 G_A: 1.043 cycle_A: 1.126 idt_A: 0.651 D_B: 0.329 G_B: 0.163 cycle_B: 1.500 idt_B: 0.517 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5300, time: 0.182, data: 0.001) D_A: 0.413 G_A: 0.452 cycle_A: 2.537 idt_A: 0.518 D_B: 0.422 G_B: 0.436 cycle_B: 1.070 idt_B: 1.059 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5400, time: 0.183, data: 0.001) D_A: 0.302 G_A: 0.310 cycle_A: 1.111 idt_A: 0.657 D_B: 0.131 G_B: 0.451 cycle_B: 1.259 idt_B: 0.536 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5500, time: 0.182, data: 0.002) D_A: 0.263 G_A: 0.423 cycle_A: 1.940 idt_A: 0.991 D_B: 0.106 G_B: 0.678 cycle_B: 2.682 idt_B: 0.576 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5600, time: 0.540, data: 0.001) D_A: 0.080 G_A: 0.265 cycle_A: 3.118 idt_A: 0.515 D_B: 0.110 G_B: 0.332 cycle_B: 1.614 idt_B: 0.934 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5700, time: 0.182, data: 0.001) D_A: 0.294 G_A: 0.171 cycle_A: 1.961 idt_A: 1.057 D_B: 0.285 G_B: 0.284 cycle_B: 2.806 idt_B: 0.722 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5800, time: 0.182, data: 0.001) D_A: 0.260 G_A: 0.363 cycle_A: 1.834 idt_A: 0.501 D_B: 0.262 G_B: 0.570 cycle_B: 1.125 idt_B: 0.818 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 5900, time: 0.182, data: 0.001) D_A: 0.371 G_A: 0.209 cycle_A: 0.686 idt_A: 0.664 D_B: 0.251 G_B: 0.381 cycle_B: 1.552 idt_B: 0.327 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 6000, time: 0.524, data: 0.002) D_A: 0.375 G_A: 0.213 cycle_A: 1.560 idt_A: 0.483 D_B: 0.115 G_B: 0.279 cycle_B: 0.980 idt_B: 0.648 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 6100, time: 0.182, data: 0.002) D_A: 0.236 G_A: 0.497 cycle_A: 1.012 idt_A: 0.587 D_B: 0.332 G_B: 0.285 cycle_B: 1.436 idt_B: 0.466 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 6200, time: 0.182, data: 0.002) D_A: 0.207 G_A: 0.386 cycle_A: 1.481 idt_A: 0.853 D_B: 0.158 G_B: 0.510 cycle_B: 1.867 idt_B: 0.749 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 6300, time: 0.182, data: 0.001) D_A: 0.147 G_A: 0.357 cycle_A: 1.745 idt_A: 0.653 D_B: 0.192 G_B: 0.627 cycle_B: 1.374 idt_B: 0.762 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 6400, time: 0.516, data: 0.002) D_A: 0.265 G_A: 0.359 cycle_A: 1.407 idt_A: 0.601 D_B: 0.146 G_B: 0.523 cycle_B: 1.504 idt_B: 0.648 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 6500, time: 0.182, data: 0.002) D_A: 0.059 G_A: 0.266 cycle_A: 1.174 idt_A: 0.906 D_B: 0.139 G_B: 0.834 cycle_B: 1.909 idt_B: 0.507 \u001b[0m\n",
      "\u001b[31m(epoch: 1, iters: 6600, time: 0.182, data: 0.001) D_A: 0.076 G_A: 1.128 cycle_A: 1.074 idt_A: 0.533 D_B: 0.151 G_B: 0.576 cycle_B: 1.475 idt_B: 0.467 \u001b[0m\n",
      "\u001b[31mEnd of epoch 1 / 200 #011 Time Taken: 1226 sec\u001b[0m\n",
      "\u001b[31mlearning rate = 0.0002000\u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 60, time: 0.182, data: 0.001) D_A: 0.354 G_A: 0.106 cycle_A: 1.627 idt_A: 0.452 D_B: 0.288 G_B: 0.244 cycle_B: 0.927 idt_B: 0.692 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 160, time: 0.544, data: 0.002) D_A: 0.360 G_A: 0.300 cycle_A: 1.619 idt_A: 0.478 D_B: 0.183 G_B: 0.114 cycle_B: 1.002 idt_B: 0.812 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 260, time: 0.182, data: 0.002) D_A: 0.317 G_A: 0.445 cycle_A: 2.348 idt_A: 0.627 D_B: 0.321 G_B: 0.634 cycle_B: 1.260 idt_B: 0.855 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 360, time: 0.182, data: 0.001) D_A: 0.138 G_A: 0.816 cycle_A: 0.980 idt_A: 0.491 D_B: 0.075 G_B: 0.447 cycle_B: 1.155 idt_B: 0.422 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 460, time: 0.182, data: 0.002) D_A: 0.291 G_A: 0.544 cycle_A: 3.368 idt_A: 0.451 D_B: 0.179 G_B: 0.263 cycle_B: 1.386 idt_B: 1.105 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 560, time: 0.543, data: 0.002) D_A: 0.097 G_A: 0.873 cycle_A: 1.584 idt_A: 0.670 D_B: 0.128 G_B: 0.504 cycle_B: 1.068 idt_B: 0.830 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 660, time: 0.182, data: 0.002) D_A: 0.122 G_A: 0.146 cycle_A: 1.875 idt_A: 0.585 D_B: 0.227 G_B: 0.348 cycle_B: 1.128 idt_B: 0.723 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 760, time: 0.183, data: 0.001) D_A: 0.277 G_A: 0.988 cycle_A: 1.188 idt_A: 0.768 D_B: 0.186 G_B: 0.326 cycle_B: 1.631 idt_B: 0.482 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 860, time: 0.181, data: 0.002) D_A: 0.160 G_A: 0.485 cycle_A: 1.135 idt_A: 0.363 D_B: 0.183 G_B: 0.219 cycle_B: 0.722 idt_B: 0.503 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 960, time: 0.643, data: 0.001) D_A: 0.334 G_A: 0.563 cycle_A: 2.240 idt_A: 1.120 D_B: 0.203 G_B: 0.163 cycle_B: 2.505 idt_B: 1.024 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1060, time: 0.182, data: 0.002) D_A: 0.321 G_A: 0.268 cycle_A: 1.513 idt_A: 0.590 D_B: 0.119 G_B: 0.139 cycle_B: 1.169 idt_B: 0.823 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1160, time: 0.182, data: 0.002) D_A: 0.250 G_A: 0.157 cycle_A: 1.085 idt_A: 0.398 D_B: 0.222 G_B: 0.287 cycle_B: 1.048 idt_B: 0.503 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1260, time: 0.182, data: 0.001) D_A: 0.296 G_A: 0.079 cycle_A: 1.011 idt_A: 0.604 D_B: 0.179 G_B: 0.282 cycle_B: 1.578 idt_B: 0.552 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1360, time: 0.549, data: 0.001) D_A: 0.332 G_A: 0.227 cycle_A: 2.969 idt_A: 0.793 D_B: 0.410 G_B: 0.587 cycle_B: 1.463 idt_B: 1.120 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1460, time: 0.182, data: 0.002) D_A: 0.126 G_A: 0.145 cycle_A: 1.668 idt_A: 0.623 D_B: 0.238 G_B: 0.228 cycle_B: 1.386 idt_B: 0.830 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1560, time: 0.182, data: 0.001) D_A: 0.131 G_A: 0.455 cycle_A: 0.977 idt_A: 0.510 D_B: 0.203 G_B: 0.237 cycle_B: 0.933 idt_B: 0.404 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1660, time: 0.182, data: 0.001) D_A: 0.087 G_A: 0.507 cycle_A: 2.149 idt_A: 1.184 D_B: 0.102 G_B: 0.499 cycle_B: 2.463 idt_B: 1.101 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1760, time: 0.664, data: 0.002) D_A: 0.188 G_A: 0.368 cycle_A: 1.085 idt_A: 0.776 D_B: 0.119 G_B: 0.390 cycle_B: 1.560 idt_B: 0.554 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1860, time: 0.182, data: 0.002) D_A: 0.333 G_A: 0.366 cycle_A: 2.110 idt_A: 0.618 D_B: 0.130 G_B: 1.358 cycle_B: 1.303 idt_B: 0.890 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 1960, time: 0.182, data: 0.001) D_A: 0.238 G_A: 0.164 cycle_A: 1.880 idt_A: 0.440 D_B: 0.215 G_B: 0.851 cycle_B: 1.055 idt_B: 0.753 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 2060, time: 0.182, data: 0.002) D_A: 0.130 G_A: 0.206 cycle_A: 1.588 idt_A: 0.391 D_B: 0.173 G_B: 0.349 cycle_B: 1.003 idt_B: 0.752 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 2160, time: 0.531, data: 0.002) D_A: 0.150 G_A: 0.272 cycle_A: 0.990 idt_A: 0.406 D_B: 0.232 G_B: 0.327 cycle_B: 0.775 idt_B: 0.460 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 2260, time: 0.182, data: 0.002) D_A: 0.099 G_A: 0.346 cycle_A: 1.454 idt_A: 0.814 D_B: 0.375 G_B: 0.893 cycle_B: 2.410 idt_B: 0.680 \u001b[0m\n",
      "\u001b[31m(epoch: 2, iters: 2360, time: 0.182, data: 0.001) D_A: 0.142 G_A: 0.379 cycle_A: 2.015 idt_A: 0.450 D_B: 0.078 G_B: 0.562 cycle_B: 0.952 idt_B: 0.879 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pytorch_estimator.fit({'training': 's3://{}/celebA/Img/img_align_celeba/train'.format(BUCKET)})\n",
    "pytorch_estimator.fit({'training': 's3://{}/cityscapes/'.format(BUCKET)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output will be in S3://BUCKET/cityscapes/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   SageMaker-CycleGAN.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../pytorch-CycleGAN-and-pix2pix-master/options/base_options.py\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master c41a4bc] Fixes\n",
      " Committer: EC2 Default User <ec2-user@ip-172-16-58-140.eu-west-1.compute.internal>\n",
      "Your name and email address were configured automatically based\n",
      "on your username and hostname. Please check that they are accurate.\n",
      "You can suppress this message by setting them explicitly:\n",
      "\n",
      "    git config --global user.name \"Your Name\"\n",
      "    git config --global user.email you@example.com\n",
      "\n",
      "After doing this, you may fix the identity used for this commit with:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 2 files changed, 270 insertions(+), 328 deletions(-)\n",
      " rewrite notebooks/SageMaker-CycleGAN.ipynb (68%)\n",
      "Counting objects: 7, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (7/7), done.\n",
      "Writing objects: 100% (7/7), 1.95 KiB | 1.95 MiB/s, done.\n",
      "Total 7 (delta 4), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/markstrefford/Apocalypse.git\n",
      "   b8e9654..c41a4bc  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git commit -am \"Fixes\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting objects: 8, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (8/8), done.\n",
      "Writing objects: 100% (8/8), 6.51 KiB | 6.51 MiB/s, done.\n",
      "Total 8 (delta 4), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/markstrefford/Apocalypse.git\n",
      "   05ea3bb..b8e9654  master -> master\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
